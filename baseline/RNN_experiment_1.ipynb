{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T18:57:25.579069Z",
     "start_time": "2017-05-06T18:57:25.455726Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "## Utilities\n",
    "import random\n",
    "\n",
    "## Libraries\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T18:57:25.582917Z",
     "start_time": "2017-05-06T18:57:25.580329Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Normalization on ImageNet mean/std for finetuning\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "save_dir = './snapshots'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T18:57:26.107434Z",
     "start_time": "2017-05-06T18:57:25.584027Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting random seeds for reproducibility. (Caveat, some CuDNN algorithms are non-deterministic)\n",
    "torch.manual_seed(1337)\n",
    "torch.cuda.manual_seed(1337)\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T18:57:26.114413Z",
     "start_time": "2017-05-06T18:57:26.109005Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Normalization only for validation and test\n",
    "ds_transform_raw = transforms.Compose([\n",
    "                     transforms.CenterCrop(224),\n",
    "                     transforms.ToTensor(),\n",
    "                     normalize\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:12:06.896968Z",
     "start_time": "2017-05-06T19:12:06.885442Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model from best iteration\n",
    "from src.p_neuro import ResNet50\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    ## We use ResNet weights from PyCaffe.\n",
    "    def __init__(self, embed_size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Loading pretrained ResNet as feature extractor\n",
    "        original_model = ResNet50(17)\n",
    "        model_path = './snapshots/2017-05-06_1235-cloud-habitation-PowerPIL-model_best.pth'\n",
    "        checkpoint = torch.load(model_path)\n",
    "        original_model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        # Everything except the last linear layer\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-1])\n",
    "        \n",
    "        # Freeze those weights\n",
    "        for p in self.features.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Get number of features of last layer\n",
    "        num_feats = original_model.classifier[0].in_features\n",
    "            \n",
    "        self.fc = nn.Linear(num_feats, embed_size)\n",
    "        self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.features(x)\n",
    "        f = f.view(f.size(0), -1)\n",
    "        out = self.fc(f)\n",
    "        out = self.bn(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:12:08.919347Z",
     "start_time": "2017-05-06T19:12:07.431937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoderCNN = CNN(2048).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:12:08.922481Z",
     "start_time": "2017-05-06T19:12:08.920546Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.init import kaiming_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:37:08.514664Z",
     "start_time": "2017-05-06T19:37:08.507521Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, num_feats, num_classes, hidden_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=num_feats,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first = True)\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Init of last layer\n",
    "        kaiming_normal(self.classifier.weight)\n",
    "    \n",
    "\n",
    "    def forward(self, feats, hidden=None):\n",
    "        x, hidden = self.rnn(feats.unsqueeze(1), hidden)\n",
    "        x = x.view(-1, self.hidden_size)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:37:09.236010Z",
     "start_time": "2017-05-06T19:37:09.227380Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoderRNN = DecoderRNN(2048, 17, 64, 10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:37:09.888453Z",
     "start_time": "2017-05-06T19:37:09.883933Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Normalization on ImageNet mean/std for finetuning\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Note, p_training has lr_decay automated\n",
    "optimizer = optim.SGD(decoderRNN.parameters(), lr=1e-1, momentum=0.9) # Finetuning whole model\n",
    "\n",
    "# criterion = ConvolutedLoss()\n",
    "criterion = torch.nn.MultiLabelSoftMarginLoss(\n",
    "    weight = torch.from_numpy(\n",
    "                 1/np.array([1,  3,  2,  1,\n",
    "                             1,  3,  2,  3,\n",
    "                             4,  4,  1,  2,\n",
    "                             1,  1,  3,  4,  1])\n",
    "    )).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:37:10.454299Z",
     "start_time": "2017-05-06T19:37:10.451752Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.p_data_augmentation import PowerPIL\n",
    "from src.p2_dataload import KaggleAmazonDataset\n",
    "from src.p_model_selection import train_valid_split\n",
    "from src.p_sampler import SubsetSampler, balance_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:37:11.149969Z",
     "start_time": "2017-05-06T19:37:10.773470Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting random seeds for reproducibility. (Caveat, some CuDNN algorithms are non-deterministic)\n",
    "torch.manual_seed(1337)\n",
    "torch.cuda.manual_seed(1337)\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "##############################################################\n",
    "## Loading the dataset\n",
    "\n",
    "## Augmentation + Normalization for full training\n",
    "ds_transform_augmented = transforms.Compose([\n",
    "                 transforms.RandomSizedCrop(224),\n",
    "                 PowerPIL(),\n",
    "                 transforms.ToTensor(),\n",
    "                 normalize\n",
    "])\n",
    "\n",
    "## Normalization only for validation and test\n",
    "ds_transform_raw = transforms.Compose([\n",
    "                 transforms.Scale(224),\n",
    "                 transforms.ToTensor(),\n",
    "                 normalize\n",
    "                 ])\n",
    "\n",
    "####     #########     ########     ###########     #####\n",
    "\n",
    "X_train = KaggleAmazonDataset('./data/train.csv','./data/train-jpg/','.jpg',\n",
    "                             ds_transform_augmented\n",
    "                             )\n",
    "X_val = KaggleAmazonDataset('./data/train.csv','./data/train-jpg/','.jpg',\n",
    "                             ds_transform_raw\n",
    "                             )\n",
    "\n",
    "# Creating a validation split\n",
    "train_idx, valid_idx = train_valid_split(X_train, 0.2)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetSampler(valid_idx)\n",
    "\n",
    "######    ##########    ##########    ########    #########\n",
    "\n",
    "# Both dataloader loads from the same dataset but with different indices\n",
    "train_loader = DataLoader(X_train,\n",
    "                      batch_size=batch_size,\n",
    "                      sampler=train_sampler,\n",
    "                      num_workers=4,\n",
    "                      pin_memory=True)\n",
    "\n",
    "valid_loader = DataLoader(X_val,\n",
    "                      batch_size=batch_size,\n",
    "                      sampler=valid_sampler,\n",
    "                      num_workers=4,\n",
    "                      pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:37:11.358273Z",
     "start_time": "2017-05-06T19:37:11.352047Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, encoder, decoder, criterion, optimizer):\n",
    "    encoder.eval()\n",
    "    decoder.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "        data, target = Variable(data), Variable(target, requires_grad=False)\n",
    "        optimizer.zero_grad()\n",
    "        encoded = encoder(data)\n",
    "        output = decoder(encoded)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T19:51:05.592592Z",
     "start_time": "2017-05-06T19:37:12.612141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.435556\n",
      "Train Epoch: 1 [640/40479 (2%)]\tLoss: 0.409556\n",
      "Train Epoch: 1 [1280/40479 (4%)]\tLoss: 0.369687\n",
      "Train Epoch: 1 [1920/40479 (6%)]\tLoss: 0.339583\n",
      "Train Epoch: 1 [2560/40479 (8%)]\tLoss: 0.303115\n",
      "Train Epoch: 1 [3200/40479 (10%)]\tLoss: 0.287817\n",
      "Train Epoch: 1 [3840/40479 (12%)]\tLoss: 0.251417\n",
      "Train Epoch: 1 [4480/40479 (14%)]\tLoss: 0.244486\n",
      "Train Epoch: 1 [5120/40479 (16%)]\tLoss: 0.251688\n",
      "Train Epoch: 1 [5760/40479 (18%)]\tLoss: 0.218834\n",
      "Train Epoch: 1 [6400/40479 (20%)]\tLoss: 0.228922\n",
      "Train Epoch: 1 [7040/40479 (22%)]\tLoss: 0.257038\n",
      "Train Epoch: 1 [7680/40479 (24%)]\tLoss: 0.240509\n",
      "Train Epoch: 1 [8320/40479 (26%)]\tLoss: 0.249612\n",
      "Train Epoch: 1 [8960/40479 (28%)]\tLoss: 0.212539\n",
      "Train Epoch: 1 [9600/40479 (30%)]\tLoss: 0.213244\n",
      "Train Epoch: 1 [10240/40479 (32%)]\tLoss: 0.232863\n",
      "Train Epoch: 1 [10880/40479 (34%)]\tLoss: 0.229000\n",
      "Train Epoch: 1 [11520/40479 (36%)]\tLoss: 0.217483\n",
      "Train Epoch: 1 [12160/40479 (38%)]\tLoss: 0.240352\n",
      "Train Epoch: 1 [12800/40479 (40%)]\tLoss: 0.228196\n",
      "Train Epoch: 1 [13440/40479 (42%)]\tLoss: 0.215130\n",
      "Train Epoch: 1 [14080/40479 (43%)]\tLoss: 0.215860\n",
      "Train Epoch: 1 [14720/40479 (45%)]\tLoss: 0.209214\n",
      "Train Epoch: 1 [15360/40479 (47%)]\tLoss: 0.213253\n",
      "Train Epoch: 1 [16000/40479 (49%)]\tLoss: 0.215986\n",
      "Train Epoch: 1 [16640/40479 (51%)]\tLoss: 0.204092\n",
      "Train Epoch: 1 [17280/40479 (53%)]\tLoss: 0.217447\n",
      "Train Epoch: 1 [17920/40479 (55%)]\tLoss: 0.224149\n",
      "Train Epoch: 1 [18560/40479 (57%)]\tLoss: 0.208092\n",
      "Train Epoch: 1 [19200/40479 (59%)]\tLoss: 0.208012\n",
      "Train Epoch: 1 [19840/40479 (61%)]\tLoss: 0.228090\n",
      "Train Epoch: 1 [20480/40479 (63%)]\tLoss: 0.227201\n",
      "Train Epoch: 1 [21120/40479 (65%)]\tLoss: 0.218654\n",
      "Train Epoch: 1 [21760/40479 (67%)]\tLoss: 0.245048\n",
      "Train Epoch: 1 [22400/40479 (69%)]\tLoss: 0.210235\n",
      "Train Epoch: 1 [23040/40479 (71%)]\tLoss: 0.247935\n",
      "Train Epoch: 1 [23680/40479 (73%)]\tLoss: 0.236987\n",
      "Train Epoch: 1 [24320/40479 (75%)]\tLoss: 0.216959\n",
      "Train Epoch: 1 [24960/40479 (77%)]\tLoss: 0.235669\n",
      "Train Epoch: 1 [25600/40479 (79%)]\tLoss: 0.226261\n",
      "Train Epoch: 1 [26240/40479 (81%)]\tLoss: 0.234269\n",
      "Train Epoch: 1 [26880/40479 (83%)]\tLoss: 0.218615\n",
      "Train Epoch: 1 [27520/40479 (85%)]\tLoss: 0.207581\n",
      "Train Epoch: 1 [28160/40479 (87%)]\tLoss: 0.211591\n",
      "Train Epoch: 1 [28800/40479 (89%)]\tLoss: 0.204346\n",
      "Train Epoch: 1 [29440/40479 (91%)]\tLoss: 0.221209\n",
      "Train Epoch: 1 [30080/40479 (93%)]\tLoss: 0.231252\n",
      "Train Epoch: 1 [30720/40479 (95%)]\tLoss: 0.233583\n",
      "Train Epoch: 1 [31360/40479 (97%)]\tLoss: 0.213050\n",
      "Train Epoch: 1 [32000/40479 (99%)]\tLoss: 0.208800\n",
      "Train Epoch: 2 [0/40479 (0%)]\tLoss: 0.221830\n",
      "Train Epoch: 2 [640/40479 (2%)]\tLoss: 0.226345\n",
      "Train Epoch: 2 [1280/40479 (4%)]\tLoss: 0.236332\n",
      "Train Epoch: 2 [1920/40479 (6%)]\tLoss: 0.220857\n",
      "Train Epoch: 2 [2560/40479 (8%)]\tLoss: 0.199616\n",
      "Train Epoch: 2 [3200/40479 (10%)]\tLoss: 0.217765\n",
      "Train Epoch: 2 [3840/40479 (12%)]\tLoss: 0.224895\n",
      "Train Epoch: 2 [4480/40479 (14%)]\tLoss: 0.192970\n",
      "Train Epoch: 2 [5120/40479 (16%)]\tLoss: 0.223005\n",
      "Train Epoch: 2 [5760/40479 (18%)]\tLoss: 0.221301\n",
      "Train Epoch: 2 [6400/40479 (20%)]\tLoss: 0.232181\n",
      "Train Epoch: 2 [7040/40479 (22%)]\tLoss: 0.223385\n",
      "Train Epoch: 2 [7680/40479 (24%)]\tLoss: 0.221813\n",
      "Train Epoch: 2 [8320/40479 (26%)]\tLoss: 0.224682\n",
      "Train Epoch: 2 [8960/40479 (28%)]\tLoss: 0.222579\n",
      "Train Epoch: 2 [9600/40479 (30%)]\tLoss: 0.200874\n",
      "Train Epoch: 2 [10240/40479 (32%)]\tLoss: 0.214944\n",
      "Train Epoch: 2 [10880/40479 (34%)]\tLoss: 0.207476\n",
      "Train Epoch: 2 [11520/40479 (36%)]\tLoss: 0.220802\n",
      "Train Epoch: 2 [12160/40479 (38%)]\tLoss: 0.221033\n",
      "Train Epoch: 2 [12800/40479 (40%)]\tLoss: 0.197412\n",
      "Train Epoch: 2 [13440/40479 (42%)]\tLoss: 0.231282\n",
      "Train Epoch: 2 [14080/40479 (43%)]\tLoss: 0.219897\n",
      "Train Epoch: 2 [14720/40479 (45%)]\tLoss: 0.215508\n",
      "Train Epoch: 2 [15360/40479 (47%)]\tLoss: 0.213763\n",
      "Train Epoch: 2 [16000/40479 (49%)]\tLoss: 0.226117\n",
      "Train Epoch: 2 [16640/40479 (51%)]\tLoss: 0.209263\n",
      "Train Epoch: 2 [17280/40479 (53%)]\tLoss: 0.221371\n",
      "Train Epoch: 2 [17920/40479 (55%)]\tLoss: 0.203588\n",
      "Train Epoch: 2 [18560/40479 (57%)]\tLoss: 0.208028\n",
      "Train Epoch: 2 [19200/40479 (59%)]\tLoss: 0.240881\n",
      "Train Epoch: 2 [19840/40479 (61%)]\tLoss: 0.219481\n",
      "Train Epoch: 2 [20480/40479 (63%)]\tLoss: 0.224081\n",
      "Train Epoch: 2 [21120/40479 (65%)]\tLoss: 0.226633\n",
      "Train Epoch: 2 [21760/40479 (67%)]\tLoss: 0.209731\n",
      "Train Epoch: 2 [22400/40479 (69%)]\tLoss: 0.196602\n",
      "Train Epoch: 2 [23040/40479 (71%)]\tLoss: 0.224780\n",
      "Train Epoch: 2 [23680/40479 (73%)]\tLoss: 0.221504\n",
      "Train Epoch: 2 [24320/40479 (75%)]\tLoss: 0.196250\n",
      "Train Epoch: 2 [24960/40479 (77%)]\tLoss: 0.209817\n",
      "Train Epoch: 2 [25600/40479 (79%)]\tLoss: 0.215482\n",
      "Train Epoch: 2 [26240/40479 (81%)]\tLoss: 0.245271\n",
      "Train Epoch: 2 [26880/40479 (83%)]\tLoss: 0.240716\n",
      "Train Epoch: 2 [27520/40479 (85%)]\tLoss: 0.234947\n",
      "Train Epoch: 2 [28160/40479 (87%)]\tLoss: 0.207777\n",
      "Train Epoch: 2 [28800/40479 (89%)]\tLoss: 0.217220\n",
      "Train Epoch: 2 [29440/40479 (91%)]\tLoss: 0.225086\n",
      "Train Epoch: 2 [30080/40479 (93%)]\tLoss: 0.200565\n",
      "Train Epoch: 2 [30720/40479 (95%)]\tLoss: 0.245808\n",
      "Train Epoch: 2 [31360/40479 (97%)]\tLoss: 0.217046\n",
      "Train Epoch: 2 [32000/40479 (99%)]\tLoss: 0.228471\n",
      "Train Epoch: 3 [0/40479 (0%)]\tLoss: 0.251557\n",
      "Train Epoch: 3 [640/40479 (2%)]\tLoss: 0.232586\n",
      "Train Epoch: 3 [1280/40479 (4%)]\tLoss: 0.202972\n",
      "Train Epoch: 3 [1920/40479 (6%)]\tLoss: 0.223908\n",
      "Train Epoch: 3 [2560/40479 (8%)]\tLoss: 0.201460\n",
      "Train Epoch: 3 [3200/40479 (10%)]\tLoss: 0.214049\n",
      "Train Epoch: 3 [3840/40479 (12%)]\tLoss: 0.208666\n",
      "Train Epoch: 3 [4480/40479 (14%)]\tLoss: 0.195132\n",
      "Train Epoch: 3 [5120/40479 (16%)]\tLoss: 0.253805\n",
      "Train Epoch: 3 [5760/40479 (18%)]\tLoss: 0.200275\n",
      "Train Epoch: 3 [6400/40479 (20%)]\tLoss: 0.211788\n",
      "Train Epoch: 3 [7040/40479 (22%)]\tLoss: 0.223072\n",
      "Train Epoch: 3 [7680/40479 (24%)]\tLoss: 0.238602\n",
      "Train Epoch: 3 [8320/40479 (26%)]\tLoss: 0.219171\n",
      "Train Epoch: 3 [8960/40479 (28%)]\tLoss: 0.233595\n",
      "Train Epoch: 3 [9600/40479 (30%)]\tLoss: 0.215720\n",
      "Train Epoch: 3 [10240/40479 (32%)]\tLoss: 0.237069\n",
      "Train Epoch: 3 [10880/40479 (34%)]\tLoss: 0.219968\n",
      "Train Epoch: 3 [11520/40479 (36%)]\tLoss: 0.210888\n",
      "Train Epoch: 3 [12160/40479 (38%)]\tLoss: 0.251297\n",
      "Train Epoch: 3 [12800/40479 (40%)]\tLoss: 0.202935\n",
      "Train Epoch: 3 [13440/40479 (42%)]\tLoss: 0.212312\n",
      "Train Epoch: 3 [14080/40479 (43%)]\tLoss: 0.232535\n",
      "Train Epoch: 3 [14720/40479 (45%)]\tLoss: 0.229978\n",
      "Train Epoch: 3 [15360/40479 (47%)]\tLoss: 0.226644\n",
      "Train Epoch: 3 [16000/40479 (49%)]\tLoss: 0.222986\n",
      "Train Epoch: 3 [16640/40479 (51%)]\tLoss: 0.216303\n",
      "Train Epoch: 3 [17280/40479 (53%)]\tLoss: 0.214122\n",
      "Train Epoch: 3 [17920/40479 (55%)]\tLoss: 0.226599\n",
      "Train Epoch: 3 [18560/40479 (57%)]\tLoss: 0.245155\n",
      "Train Epoch: 3 [19200/40479 (59%)]\tLoss: 0.217142\n",
      "Train Epoch: 3 [19840/40479 (61%)]\tLoss: 0.237862\n",
      "Train Epoch: 3 [20480/40479 (63%)]\tLoss: 0.210611\n",
      "Train Epoch: 3 [21120/40479 (65%)]\tLoss: 0.210613\n",
      "Train Epoch: 3 [21760/40479 (67%)]\tLoss: 0.220819\n",
      "Train Epoch: 3 [22400/40479 (69%)]\tLoss: 0.206627\n",
      "Train Epoch: 3 [23040/40479 (71%)]\tLoss: 0.218339\n",
      "Train Epoch: 3 [23680/40479 (73%)]\tLoss: 0.211441\n",
      "Train Epoch: 3 [24320/40479 (75%)]\tLoss: 0.205327\n",
      "Train Epoch: 3 [24960/40479 (77%)]\tLoss: 0.204353\n",
      "Train Epoch: 3 [25600/40479 (79%)]\tLoss: 0.206513\n",
      "Train Epoch: 3 [26240/40479 (81%)]\tLoss: 0.217377\n",
      "Train Epoch: 3 [26880/40479 (83%)]\tLoss: 0.227448\n",
      "Train Epoch: 3 [27520/40479 (85%)]\tLoss: 0.204768\n",
      "Train Epoch: 3 [28160/40479 (87%)]\tLoss: 0.212927\n",
      "Train Epoch: 3 [28800/40479 (89%)]\tLoss: 0.238617\n",
      "Train Epoch: 3 [29440/40479 (91%)]\tLoss: 0.206868\n",
      "Train Epoch: 3 [30080/40479 (93%)]\tLoss: 0.224896\n",
      "Train Epoch: 3 [30720/40479 (95%)]\tLoss: 0.215602\n",
      "Train Epoch: 3 [31360/40479 (97%)]\tLoss: 0.230982\n",
      "Train Epoch: 3 [32000/40479 (99%)]\tLoss: 0.221313\n",
      "Train Epoch: 4 [0/40479 (0%)]\tLoss: 0.209418\n",
      "Train Epoch: 4 [640/40479 (2%)]\tLoss: 0.218788\n",
      "Train Epoch: 4 [1280/40479 (4%)]\tLoss: 0.244478\n",
      "Train Epoch: 4 [1920/40479 (6%)]\tLoss: 0.213261\n",
      "Train Epoch: 4 [2560/40479 (8%)]\tLoss: 0.205852\n",
      "Train Epoch: 4 [3200/40479 (10%)]\tLoss: 0.238808\n",
      "Train Epoch: 4 [3840/40479 (12%)]\tLoss: 0.210391\n",
      "Train Epoch: 4 [4480/40479 (14%)]\tLoss: 0.228555\n",
      "Train Epoch: 4 [5120/40479 (16%)]\tLoss: 0.202205\n",
      "Train Epoch: 4 [5760/40479 (18%)]\tLoss: 0.244985\n",
      "Train Epoch: 4 [6400/40479 (20%)]\tLoss: 0.225250\n",
      "Train Epoch: 4 [7040/40479 (22%)]\tLoss: 0.228128\n",
      "Train Epoch: 4 [7680/40479 (24%)]\tLoss: 0.201752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [8320/40479 (26%)]\tLoss: 0.192985\n",
      "Train Epoch: 4 [8960/40479 (28%)]\tLoss: 0.232153\n",
      "Train Epoch: 4 [9600/40479 (30%)]\tLoss: 0.209456\n",
      "Train Epoch: 4 [10240/40479 (32%)]\tLoss: 0.212727\n",
      "Train Epoch: 4 [10880/40479 (34%)]\tLoss: 0.218378\n",
      "Train Epoch: 4 [11520/40479 (36%)]\tLoss: 0.216620\n",
      "Train Epoch: 4 [12160/40479 (38%)]\tLoss: 0.208027\n",
      "Train Epoch: 4 [12800/40479 (40%)]\tLoss: 0.234140\n",
      "Train Epoch: 4 [13440/40479 (42%)]\tLoss: 0.216869\n",
      "Train Epoch: 4 [14080/40479 (43%)]\tLoss: 0.192126\n",
      "Train Epoch: 4 [14720/40479 (45%)]\tLoss: 0.213921\n",
      "Train Epoch: 4 [15360/40479 (47%)]\tLoss: 0.208655\n",
      "Train Epoch: 4 [16000/40479 (49%)]\tLoss: 0.221401\n",
      "Train Epoch: 4 [16640/40479 (51%)]\tLoss: 0.226007\n",
      "Train Epoch: 4 [17280/40479 (53%)]\tLoss: 0.245658\n",
      "Train Epoch: 4 [17920/40479 (55%)]\tLoss: 0.216689\n",
      "Train Epoch: 4 [18560/40479 (57%)]\tLoss: 0.204786\n",
      "Train Epoch: 4 [19200/40479 (59%)]\tLoss: 0.231551\n",
      "Train Epoch: 4 [19840/40479 (61%)]\tLoss: 0.233882\n",
      "Train Epoch: 4 [20480/40479 (63%)]\tLoss: 0.237672\n",
      "Train Epoch: 4 [21120/40479 (65%)]\tLoss: 0.229086\n",
      "Train Epoch: 4 [21760/40479 (67%)]\tLoss: 0.223865\n",
      "Train Epoch: 4 [22400/40479 (69%)]\tLoss: 0.223414\n",
      "Train Epoch: 4 [23040/40479 (71%)]\tLoss: 0.232349\n",
      "Train Epoch: 4 [23680/40479 (73%)]\tLoss: 0.221572\n",
      "Train Epoch: 4 [24320/40479 (75%)]\tLoss: 0.216628\n",
      "Train Epoch: 4 [24960/40479 (77%)]\tLoss: 0.214147\n",
      "Train Epoch: 4 [25600/40479 (79%)]\tLoss: 0.225763\n",
      "Train Epoch: 4 [26240/40479 (81%)]\tLoss: 0.213933\n",
      "Train Epoch: 4 [26880/40479 (83%)]\tLoss: 0.208559\n",
      "Train Epoch: 4 [27520/40479 (85%)]\tLoss: 0.212612\n",
      "Train Epoch: 4 [28160/40479 (87%)]\tLoss: 0.209097\n",
      "Train Epoch: 4 [28800/40479 (89%)]\tLoss: 0.228192\n",
      "Train Epoch: 4 [29440/40479 (91%)]\tLoss: 0.221341\n",
      "Train Epoch: 4 [30080/40479 (93%)]\tLoss: 0.219709\n",
      "Train Epoch: 4 [30720/40479 (95%)]\tLoss: 0.216520\n",
      "Train Epoch: 4 [31360/40479 (97%)]\tLoss: 0.206181\n",
      "Train Epoch: 4 [32000/40479 (99%)]\tLoss: 0.200449\n",
      "Train Epoch: 5 [0/40479 (0%)]\tLoss: 0.202878\n",
      "Train Epoch: 5 [640/40479 (2%)]\tLoss: 0.223886\n",
      "Train Epoch: 5 [1280/40479 (4%)]\tLoss: 0.232988\n",
      "Train Epoch: 5 [1920/40479 (6%)]\tLoss: 0.212176\n",
      "Train Epoch: 5 [2560/40479 (8%)]\tLoss: 0.208125\n",
      "Train Epoch: 5 [3200/40479 (10%)]\tLoss: 0.219078\n",
      "Train Epoch: 5 [3840/40479 (12%)]\tLoss: 0.197650\n",
      "Train Epoch: 5 [4480/40479 (14%)]\tLoss: 0.218611\n",
      "Train Epoch: 5 [5120/40479 (16%)]\tLoss: 0.194874\n",
      "Train Epoch: 5 [5760/40479 (18%)]\tLoss: 0.238438\n",
      "Train Epoch: 5 [6400/40479 (20%)]\tLoss: 0.204757\n",
      "Train Epoch: 5 [7040/40479 (22%)]\tLoss: 0.207183\n",
      "Train Epoch: 5 [7680/40479 (24%)]\tLoss: 0.205667\n",
      "Train Epoch: 5 [8320/40479 (26%)]\tLoss: 0.218935\n",
      "Train Epoch: 5 [8960/40479 (28%)]\tLoss: 0.214910\n",
      "Train Epoch: 5 [9600/40479 (30%)]\tLoss: 0.245063\n",
      "Train Epoch: 5 [10240/40479 (32%)]\tLoss: 0.212979\n",
      "Train Epoch: 5 [10880/40479 (34%)]\tLoss: 0.214062\n",
      "Train Epoch: 5 [11520/40479 (36%)]\tLoss: 0.214615\n",
      "Train Epoch: 5 [12160/40479 (38%)]\tLoss: 0.208764\n",
      "Train Epoch: 5 [12800/40479 (40%)]\tLoss: 0.216662\n",
      "Train Epoch: 5 [13440/40479 (42%)]\tLoss: 0.225370\n",
      "Train Epoch: 5 [14080/40479 (43%)]\tLoss: 0.225904\n",
      "Train Epoch: 5 [14720/40479 (45%)]\tLoss: 0.237777\n",
      "Train Epoch: 5 [15360/40479 (47%)]\tLoss: 0.220133\n",
      "Train Epoch: 5 [16000/40479 (49%)]\tLoss: 0.230607\n",
      "Train Epoch: 5 [16640/40479 (51%)]\tLoss: 0.222831\n",
      "Train Epoch: 5 [17280/40479 (53%)]\tLoss: 0.246762\n",
      "Train Epoch: 5 [17920/40479 (55%)]\tLoss: 0.230246\n",
      "Train Epoch: 5 [18560/40479 (57%)]\tLoss: 0.216454\n",
      "Train Epoch: 5 [19200/40479 (59%)]\tLoss: 0.229916\n",
      "Train Epoch: 5 [19840/40479 (61%)]\tLoss: 0.201469\n",
      "Train Epoch: 5 [20480/40479 (63%)]\tLoss: 0.197106\n",
      "Train Epoch: 5 [21120/40479 (65%)]\tLoss: 0.205562\n",
      "Train Epoch: 5 [21760/40479 (67%)]\tLoss: 0.213962\n",
      "Train Epoch: 5 [22400/40479 (69%)]\tLoss: 0.211499\n",
      "Train Epoch: 5 [23040/40479 (71%)]\tLoss: 0.205921\n",
      "Train Epoch: 5 [23680/40479 (73%)]\tLoss: 0.224541\n",
      "Train Epoch: 5 [24320/40479 (75%)]\tLoss: 0.203990\n",
      "Train Epoch: 5 [24960/40479 (77%)]\tLoss: 0.200465\n",
      "Train Epoch: 5 [25600/40479 (79%)]\tLoss: 0.233774\n",
      "Train Epoch: 5 [26240/40479 (81%)]\tLoss: 0.238049\n",
      "Train Epoch: 5 [26880/40479 (83%)]\tLoss: 0.215357\n",
      "Train Epoch: 5 [27520/40479 (85%)]\tLoss: 0.239355\n",
      "Train Epoch: 5 [28160/40479 (87%)]\tLoss: 0.206513\n",
      "Train Epoch: 5 [28800/40479 (89%)]\tLoss: 0.223596\n",
      "Train Epoch: 5 [29440/40479 (91%)]\tLoss: 0.219268\n",
      "Train Epoch: 5 [30080/40479 (93%)]\tLoss: 0.217147\n",
      "Train Epoch: 5 [30720/40479 (95%)]\tLoss: 0.222204\n",
      "Train Epoch: 5 [31360/40479 (97%)]\tLoss: 0.244053\n",
      "Train Epoch: 5 [32000/40479 (99%)]\tLoss: 0.200348\n",
      "Train Epoch: 6 [0/40479 (0%)]\tLoss: 0.221157\n",
      "Train Epoch: 6 [640/40479 (2%)]\tLoss: 0.252395\n",
      "Train Epoch: 6 [1280/40479 (4%)]\tLoss: 0.241545\n",
      "Train Epoch: 6 [1920/40479 (6%)]\tLoss: 0.228716\n",
      "Train Epoch: 6 [2560/40479 (8%)]\tLoss: 0.191572\n",
      "Train Epoch: 6 [3200/40479 (10%)]\tLoss: 0.194431\n",
      "Train Epoch: 6 [3840/40479 (12%)]\tLoss: 0.239263\n",
      "Train Epoch: 6 [4480/40479 (14%)]\tLoss: 0.207937\n",
      "Train Epoch: 6 [5120/40479 (16%)]\tLoss: 0.201746\n",
      "Train Epoch: 6 [5760/40479 (18%)]\tLoss: 0.223089\n",
      "Train Epoch: 6 [6400/40479 (20%)]\tLoss: 0.215151\n",
      "Train Epoch: 6 [7040/40479 (22%)]\tLoss: 0.210253\n",
      "Train Epoch: 6 [7680/40479 (24%)]\tLoss: 0.230108\n",
      "Train Epoch: 6 [8320/40479 (26%)]\tLoss: 0.209366\n",
      "Train Epoch: 6 [8960/40479 (28%)]\tLoss: 0.195442\n",
      "Train Epoch: 6 [9600/40479 (30%)]\tLoss: 0.225066\n",
      "Train Epoch: 6 [10240/40479 (32%)]\tLoss: 0.206362\n",
      "Train Epoch: 6 [10880/40479 (34%)]\tLoss: 0.231513\n",
      "Train Epoch: 6 [11520/40479 (36%)]\tLoss: 0.224703\n",
      "Train Epoch: 6 [12160/40479 (38%)]\tLoss: 0.223797\n",
      "Train Epoch: 6 [12800/40479 (40%)]\tLoss: 0.206543\n",
      "Train Epoch: 6 [13440/40479 (42%)]\tLoss: 0.249504\n",
      "Train Epoch: 6 [14080/40479 (43%)]\tLoss: 0.215576\n",
      "Train Epoch: 6 [14720/40479 (45%)]\tLoss: 0.198119\n",
      "Train Epoch: 6 [15360/40479 (47%)]\tLoss: 0.208393\n",
      "Train Epoch: 6 [16000/40479 (49%)]\tLoss: 0.214696\n",
      "Train Epoch: 6 [16640/40479 (51%)]\tLoss: 0.203025\n",
      "Train Epoch: 6 [17280/40479 (53%)]\tLoss: 0.192496\n",
      "Train Epoch: 6 [17920/40479 (55%)]\tLoss: 0.239695\n",
      "Train Epoch: 6 [18560/40479 (57%)]\tLoss: 0.230435\n",
      "Train Epoch: 6 [19200/40479 (59%)]\tLoss: 0.204453\n",
      "Train Epoch: 6 [19840/40479 (61%)]\tLoss: 0.234823\n",
      "Train Epoch: 6 [20480/40479 (63%)]\tLoss: 0.226867\n",
      "Train Epoch: 6 [21120/40479 (65%)]\tLoss: 0.200829\n",
      "Train Epoch: 6 [21760/40479 (67%)]\tLoss: 0.227352\n",
      "Train Epoch: 6 [22400/40479 (69%)]\tLoss: 0.254058\n",
      "Train Epoch: 6 [23040/40479 (71%)]\tLoss: 0.200713\n",
      "Train Epoch: 6 [23680/40479 (73%)]\tLoss: 0.219419\n",
      "Train Epoch: 6 [24320/40479 (75%)]\tLoss: 0.211055\n",
      "Train Epoch: 6 [24960/40479 (77%)]\tLoss: 0.224809\n",
      "Train Epoch: 6 [25600/40479 (79%)]\tLoss: 0.229782\n",
      "Train Epoch: 6 [26240/40479 (81%)]\tLoss: 0.224255\n",
      "Train Epoch: 6 [26880/40479 (83%)]\tLoss: 0.214961\n",
      "Train Epoch: 6 [27520/40479 (85%)]\tLoss: 0.235325\n",
      "Train Epoch: 6 [28160/40479 (87%)]\tLoss: 0.232684\n",
      "Train Epoch: 6 [28800/40479 (89%)]\tLoss: 0.219771\n",
      "Train Epoch: 6 [29440/40479 (91%)]\tLoss: 0.206950\n",
      "Train Epoch: 6 [30080/40479 (93%)]\tLoss: 0.206973\n",
      "Train Epoch: 6 [30720/40479 (95%)]\tLoss: 0.205198\n",
      "Train Epoch: 6 [31360/40479 (97%)]\tLoss: 0.202008\n",
      "Train Epoch: 6 [32000/40479 (99%)]\tLoss: 0.237647\n",
      "Train Epoch: 7 [0/40479 (0%)]\tLoss: 0.238941\n",
      "Train Epoch: 7 [640/40479 (2%)]\tLoss: 0.206254\n",
      "Train Epoch: 7 [1280/40479 (4%)]\tLoss: 0.202189\n",
      "Train Epoch: 7 [1920/40479 (6%)]\tLoss: 0.222286\n",
      "Train Epoch: 7 [2560/40479 (8%)]\tLoss: 0.212710\n",
      "Train Epoch: 7 [3200/40479 (10%)]\tLoss: 0.261827\n",
      "Train Epoch: 7 [3840/40479 (12%)]\tLoss: 0.233636\n",
      "Train Epoch: 7 [4480/40479 (14%)]\tLoss: 0.217446\n",
      "Train Epoch: 7 [5120/40479 (16%)]\tLoss: 0.197451\n",
      "Train Epoch: 7 [5760/40479 (18%)]\tLoss: 0.218938\n",
      "Train Epoch: 7 [6400/40479 (20%)]\tLoss: 0.206823\n",
      "Train Epoch: 7 [7040/40479 (22%)]\tLoss: 0.215967\n",
      "Train Epoch: 7 [7680/40479 (24%)]\tLoss: 0.234034\n",
      "Train Epoch: 7 [8320/40479 (26%)]\tLoss: 0.222782\n",
      "Train Epoch: 7 [8960/40479 (28%)]\tLoss: 0.221467\n",
      "Train Epoch: 7 [9600/40479 (30%)]\tLoss: 0.215337\n",
      "Train Epoch: 7 [10240/40479 (32%)]\tLoss: 0.225604\n",
      "Train Epoch: 7 [10880/40479 (34%)]\tLoss: 0.243185\n",
      "Train Epoch: 7 [11520/40479 (36%)]\tLoss: 0.216148\n",
      "Train Epoch: 7 [12160/40479 (38%)]\tLoss: 0.229720\n",
      "Train Epoch: 7 [12800/40479 (40%)]\tLoss: 0.205371\n",
      "Train Epoch: 7 [13440/40479 (42%)]\tLoss: 0.222294\n",
      "Train Epoch: 7 [14080/40479 (43%)]\tLoss: 0.223919\n",
      "Train Epoch: 7 [14720/40479 (45%)]\tLoss: 0.215905\n",
      "Train Epoch: 7 [15360/40479 (47%)]\tLoss: 0.219890\n",
      "Train Epoch: 7 [16000/40479 (49%)]\tLoss: 0.232056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [16640/40479 (51%)]\tLoss: 0.211867\n",
      "Train Epoch: 7 [17280/40479 (53%)]\tLoss: 0.213061\n",
      "Train Epoch: 7 [17920/40479 (55%)]\tLoss: 0.182352\n",
      "Train Epoch: 7 [18560/40479 (57%)]\tLoss: 0.204680\n",
      "Train Epoch: 7 [19200/40479 (59%)]\tLoss: 0.204601\n",
      "Train Epoch: 7 [19840/40479 (61%)]\tLoss: 0.204036\n",
      "Train Epoch: 7 [20480/40479 (63%)]\tLoss: 0.214126\n",
      "Train Epoch: 7 [21120/40479 (65%)]\tLoss: 0.235875\n",
      "Train Epoch: 7 [21760/40479 (67%)]\tLoss: 0.211310\n",
      "Train Epoch: 7 [22400/40479 (69%)]\tLoss: 0.219646\n",
      "Train Epoch: 7 [23040/40479 (71%)]\tLoss: 0.223003\n",
      "Train Epoch: 7 [23680/40479 (73%)]\tLoss: 0.220125\n",
      "Train Epoch: 7 [24320/40479 (75%)]\tLoss: 0.221888\n",
      "Train Epoch: 7 [24960/40479 (77%)]\tLoss: 0.193348\n",
      "Train Epoch: 7 [25600/40479 (79%)]\tLoss: 0.231392\n",
      "Train Epoch: 7 [26240/40479 (81%)]\tLoss: 0.215880\n",
      "Train Epoch: 7 [26880/40479 (83%)]\tLoss: 0.220085\n",
      "Train Epoch: 7 [27520/40479 (85%)]\tLoss: 0.259755\n",
      "Train Epoch: 7 [28160/40479 (87%)]\tLoss: 0.229210\n",
      "Train Epoch: 7 [28800/40479 (89%)]\tLoss: 0.228965\n",
      "Train Epoch: 7 [29440/40479 (91%)]\tLoss: 0.238347\n",
      "Train Epoch: 7 [30080/40479 (93%)]\tLoss: 0.237505\n",
      "Train Epoch: 7 [30720/40479 (95%)]\tLoss: 0.242703\n",
      "Train Epoch: 7 [31360/40479 (97%)]\tLoss: 0.201824\n",
      "Train Epoch: 7 [32000/40479 (99%)]\tLoss: 0.222159\n",
      "Train Epoch: 8 [0/40479 (0%)]\tLoss: 0.210300\n",
      "Train Epoch: 8 [640/40479 (2%)]\tLoss: 0.213195\n",
      "Train Epoch: 8 [1280/40479 (4%)]\tLoss: 0.236923\n",
      "Train Epoch: 8 [1920/40479 (6%)]\tLoss: 0.214789\n",
      "Train Epoch: 8 [2560/40479 (8%)]\tLoss: 0.189022\n",
      "Train Epoch: 8 [3200/40479 (10%)]\tLoss: 0.202073\n",
      "Train Epoch: 8 [3840/40479 (12%)]\tLoss: 0.223525\n",
      "Train Epoch: 8 [4480/40479 (14%)]\tLoss: 0.212316\n",
      "Train Epoch: 8 [5120/40479 (16%)]\tLoss: 0.197626\n",
      "Train Epoch: 8 [5760/40479 (18%)]\tLoss: 0.229944\n",
      "Train Epoch: 8 [6400/40479 (20%)]\tLoss: 0.208881\n",
      "Train Epoch: 8 [7040/40479 (22%)]\tLoss: 0.222905\n",
      "Train Epoch: 8 [7680/40479 (24%)]\tLoss: 0.215646\n",
      "Train Epoch: 8 [8320/40479 (26%)]\tLoss: 0.208961\n",
      "Train Epoch: 8 [8960/40479 (28%)]\tLoss: 0.201373\n",
      "Train Epoch: 8 [9600/40479 (30%)]\tLoss: 0.187059\n",
      "Train Epoch: 8 [10240/40479 (32%)]\tLoss: 0.205768\n",
      "Train Epoch: 8 [10880/40479 (34%)]\tLoss: 0.195439\n",
      "Train Epoch: 8 [11520/40479 (36%)]\tLoss: 0.229307\n",
      "Train Epoch: 8 [12160/40479 (38%)]\tLoss: 0.233949\n",
      "Train Epoch: 8 [12800/40479 (40%)]\tLoss: 0.208750\n",
      "Train Epoch: 8 [13440/40479 (42%)]\tLoss: 0.210449\n",
      "Train Epoch: 8 [14080/40479 (43%)]\tLoss: 0.223516\n",
      "Train Epoch: 8 [14720/40479 (45%)]\tLoss: 0.224399\n",
      "Train Epoch: 8 [15360/40479 (47%)]\tLoss: 0.222601\n",
      "Train Epoch: 8 [16000/40479 (49%)]\tLoss: 0.215521\n",
      "Train Epoch: 8 [16640/40479 (51%)]\tLoss: 0.217097\n",
      "Train Epoch: 8 [17280/40479 (53%)]\tLoss: 0.210878\n",
      "Train Epoch: 8 [17920/40479 (55%)]\tLoss: 0.240644\n",
      "Train Epoch: 8 [18560/40479 (57%)]\tLoss: 0.234446\n",
      "Train Epoch: 8 [19200/40479 (59%)]\tLoss: 0.220509\n",
      "Train Epoch: 8 [19840/40479 (61%)]\tLoss: 0.214906\n",
      "Train Epoch: 8 [20480/40479 (63%)]\tLoss: 0.231343\n",
      "Train Epoch: 8 [21120/40479 (65%)]\tLoss: 0.221846\n",
      "Train Epoch: 8 [21760/40479 (67%)]\tLoss: 0.231584\n",
      "Train Epoch: 8 [22400/40479 (69%)]\tLoss: 0.201782\n",
      "Train Epoch: 8 [23040/40479 (71%)]\tLoss: 0.234168\n",
      "Train Epoch: 8 [23680/40479 (73%)]\tLoss: 0.225944\n",
      "Train Epoch: 8 [24320/40479 (75%)]\tLoss: 0.219733\n",
      "Train Epoch: 8 [24960/40479 (77%)]\tLoss: 0.200213\n",
      "Train Epoch: 8 [25600/40479 (79%)]\tLoss: 0.222768\n",
      "Train Epoch: 8 [26240/40479 (81%)]\tLoss: 0.224571\n",
      "Train Epoch: 8 [26880/40479 (83%)]\tLoss: 0.227366\n",
      "Train Epoch: 8 [27520/40479 (85%)]\tLoss: 0.192402\n",
      "Train Epoch: 8 [28160/40479 (87%)]\tLoss: 0.206933\n",
      "Train Epoch: 8 [28800/40479 (89%)]\tLoss: 0.222230\n",
      "Train Epoch: 8 [29440/40479 (91%)]\tLoss: 0.241823\n",
      "Train Epoch: 8 [30080/40479 (93%)]\tLoss: 0.219849\n",
      "Train Epoch: 8 [30720/40479 (95%)]\tLoss: 0.223774\n",
      "Train Epoch: 8 [31360/40479 (97%)]\tLoss: 0.221740\n",
      "Train Epoch: 8 [32000/40479 (99%)]\tLoss: 0.226302\n",
      "Train Epoch: 9 [0/40479 (0%)]\tLoss: 0.246171\n",
      "Train Epoch: 9 [640/40479 (2%)]\tLoss: 0.194035\n",
      "Train Epoch: 9 [1280/40479 (4%)]\tLoss: 0.226316\n",
      "Train Epoch: 9 [1920/40479 (6%)]\tLoss: 0.219594\n",
      "Train Epoch: 9 [2560/40479 (8%)]\tLoss: 0.192174\n",
      "Train Epoch: 9 [3200/40479 (10%)]\tLoss: 0.208604\n",
      "Train Epoch: 9 [3840/40479 (12%)]\tLoss: 0.238914\n",
      "Train Epoch: 9 [4480/40479 (14%)]\tLoss: 0.227050\n",
      "Train Epoch: 9 [5120/40479 (16%)]\tLoss: 0.218689\n",
      "Train Epoch: 9 [5760/40479 (18%)]\tLoss: 0.241844\n",
      "Train Epoch: 9 [6400/40479 (20%)]\tLoss: 0.230105\n",
      "Train Epoch: 9 [7040/40479 (22%)]\tLoss: 0.221337\n",
      "Train Epoch: 9 [7680/40479 (24%)]\tLoss: 0.226021\n",
      "Train Epoch: 9 [8320/40479 (26%)]\tLoss: 0.206170\n",
      "Train Epoch: 9 [8960/40479 (28%)]\tLoss: 0.189948\n",
      "Train Epoch: 9 [9600/40479 (30%)]\tLoss: 0.218153\n",
      "Train Epoch: 9 [10240/40479 (32%)]\tLoss: 0.221108\n",
      "Train Epoch: 9 [10880/40479 (34%)]\tLoss: 0.200809\n",
      "Train Epoch: 9 [11520/40479 (36%)]\tLoss: 0.224982\n",
      "Train Epoch: 9 [12160/40479 (38%)]\tLoss: 0.232980\n",
      "Train Epoch: 9 [12800/40479 (40%)]\tLoss: 0.199956\n",
      "Train Epoch: 9 [13440/40479 (42%)]\tLoss: 0.225886\n",
      "Train Epoch: 9 [14080/40479 (43%)]\tLoss: 0.234917\n",
      "Train Epoch: 9 [14720/40479 (45%)]\tLoss: 0.215907\n",
      "Train Epoch: 9 [15360/40479 (47%)]\tLoss: 0.201263\n",
      "Train Epoch: 9 [16000/40479 (49%)]\tLoss: 0.200151\n",
      "Train Epoch: 9 [16640/40479 (51%)]\tLoss: 0.200983\n",
      "Train Epoch: 9 [17280/40479 (53%)]\tLoss: 0.199013\n",
      "Train Epoch: 9 [17920/40479 (55%)]\tLoss: 0.238366\n",
      "Train Epoch: 9 [18560/40479 (57%)]\tLoss: 0.212182\n",
      "Train Epoch: 9 [19200/40479 (59%)]\tLoss: 0.216866\n",
      "Train Epoch: 9 [19840/40479 (61%)]\tLoss: 0.223518\n",
      "Train Epoch: 9 [20480/40479 (63%)]\tLoss: 0.206608\n",
      "Train Epoch: 9 [21120/40479 (65%)]\tLoss: 0.221796\n",
      "Train Epoch: 9 [21760/40479 (67%)]\tLoss: 0.243650\n",
      "Train Epoch: 9 [22400/40479 (69%)]\tLoss: 0.215382\n",
      "Train Epoch: 9 [23040/40479 (71%)]\tLoss: 0.212058\n",
      "Train Epoch: 9 [23680/40479 (73%)]\tLoss: 0.225021\n",
      "Train Epoch: 9 [24320/40479 (75%)]\tLoss: 0.227688\n",
      "Train Epoch: 9 [24960/40479 (77%)]\tLoss: 0.235619\n",
      "Train Epoch: 9 [25600/40479 (79%)]\tLoss: 0.238336\n",
      "Train Epoch: 9 [26240/40479 (81%)]\tLoss: 0.207296\n",
      "Train Epoch: 9 [26880/40479 (83%)]\tLoss: 0.208340\n",
      "Train Epoch: 9 [27520/40479 (85%)]\tLoss: 0.220505\n",
      "Train Epoch: 9 [28160/40479 (87%)]\tLoss: 0.222068\n",
      "Train Epoch: 9 [28800/40479 (89%)]\tLoss: 0.221910\n",
      "Train Epoch: 9 [29440/40479 (91%)]\tLoss: 0.185835\n",
      "Train Epoch: 9 [30080/40479 (93%)]\tLoss: 0.206984\n",
      "Train Epoch: 9 [30720/40479 (95%)]\tLoss: 0.236037\n",
      "Train Epoch: 9 [31360/40479 (97%)]\tLoss: 0.230958\n",
      "Train Epoch: 9 [32000/40479 (99%)]\tLoss: 0.197022\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch, train_loader, encoderCNN, decoderRNN, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
